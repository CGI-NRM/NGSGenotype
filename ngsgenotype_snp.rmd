---
title: "ngsgenotype_snp"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Detect, load and clean files and genotypes:
```{r}
# Load libraries:
library(tidyverse)
library(ShortRead)
library(wesanderson)
source("genotyping_functions.r")

ParseGenotypes <- function(genotypePath = "Genotyped_SNPs/") {
  snpCsvFiles <- list.files(genotypePath, pattern = ".csv", full.names = TRUE)
  loadedFiles <- lapply(snpCsvFiles, read.table, sep = ',', header = TRUE, check.names = FALSE)
  loadedGenotypes <- cbind(Status = 'Loaded', do.call(rbind, loadedFiles))
  loadedGenotypes[is.na(loadedGenotypes)] <- ''
  loadedGenotypes$Sample <- toupper(loadedGenotypes$Sample)
  loadedGenotypes$Status[grepl("NEGATIVE|POSITIVE", loadedGenotypes$Sample)] <- "Control" # mark controls
  loadedGenotypes$Status[duplicated(loadedGenotypes$Sample)] <- "Duplicated" # mark duplications of names
  return(loadedGenotypes)
}

# Load all samples and mark controls and duplicates: # some negatives and positives are summarized if they are named the same(?)
allGenotypes <- ParseGenotypes(genotypePath = "Genotyped_SNPs/")
```

# Filter/QC samples and loci:
```{r}
# Filter out sex loci:
sexString <- "Ua-snp-01y|Ua-snp-02y|Ua-snp-03y|Ua-snp-04y|Ua-snp-196-x|Ua-snp-248-x|Ua-snp-236-x"
autoGenotypes <- allGenotypes[, !grepl(sexString, colnames(allGenotypes))]
saveRDS(autoGenotypes, file = "autoGenotypes.rds")
sexGenotypes <- cbind(Sample = allGenotypes$Sample, allGenotypes[, grepl(sexString, colnames(allGenotypes))])
saveRDS(sexGenotypes, file = "sexGenotypes.rds")

QCMarking <- function(inGenotypes, minPresent = 75, maxPresent = 10000, targetStatus = c(""), newStatus = "Pass") {
  nLoci <- ncol(inGenotypes) - 2
  sumEmpties <- function(x) {return(sum(grepl("^$", x)))}
  inGenotypes$Status[apply(inGenotypes, 1, sumEmpties) <= (nLoci - minPresent) & apply(inGenotypes, 1, sumEmpties) >= (nLoci - maxPresent) & grepl(paste(targetStatus, sep = "|"), inGenotypes$Status)] <- newStatus
  return(inGenotypes)
}

QCGenotypes <- QCMarking(autoGenotypes, minPresent = 75, targetStatus = c("Loaded"), newStatus = "High Quality") %>%
  QCMarking(minPresent = 67, maxPresent = 74, targetStatus = c("Loaded"), newStatus = "Medium Quality") %>%
  QCMarking(minPresent = 24, maxPresent = 66, targetStatus = c("Loaded"), newStatus = "Low Quality") %>%
  QCMarking(minPresent = 00, maxPresent = 23, targetStatus = c("Loaded"), newStatus = "Fail Quality") # perhaps use a more comprehensive function and collapse this into one line

QCGenotypes <- QCGenotypes[, !lapply(QCGenotypes, unique) == ''] # does this matter with allelematch?
```

# Collapse samples to individuals based on high quality samples (>= 75 working loci):
```{r}
library(allelematch)

LoadAMData2 <- function(inData, targetStatus = c("")) {
  # Prepare data (filter by targeted sample status and remove status column):
  inData <- inData[grepl(paste(targetStatus, sep = "|"), inData$Status), -c(1)]
  
  # Split loci into two columns:
  inData[inData == ''] <- "NN" # change missing data to NN
  splitDataset <- cbind(Sample = inData$Sample, do.call(cbind, lapply(1:ncol(inData[, -c(1)]), SplitLocus, inData[, -c(1)])))
  
  # Load data:
  snpLoadedSplit <- allelematch::amDataset(multilocusDataset = splitDataset, missingCode = "N", indexColumn = "Sample")
  bearAlleleKey <- rep(1:(ncol(splitDataset[, -c(1)]) / 2), each = 2)
  return(list(Data = snpLoadedSplit, AlleleKey = bearAlleleKey))
}

# Load data into allelematch:
loadedData75 <- LoadAMData2(QCGenotypes, targetStatus = c("High Quality")) # Load all samples with 75 or more worknig loci

# Find optimal mismatch parameters (optional to use) and save plot:
{png(file="amUniqueProfile_plot_75.png", width = 689, height = 425)
amProfile75 <- allelematch::amUniqueProfile(amDatasetFocal = loadedData75$Data, multilocusMap = loadedData75$AlleleKey, doPlot = TRUE, alleleMismatch = c(0:45)) # 13 is the best
dev.off()}
saveRDS(amProfile75, file = "amProfile75.rds")
mmCutoff <- amProfile75$alleleMismatch[amProfile75$guessOptimum]

# Cluster samples with allelematch:
# uniqueBears75 <- allelematch::amUnique(loadedData75$Data, multilocusMap = loadedData75$AlleleKey, alleleMismatch = mmCutoff) # uncomment if using calculated cutoff
uniqueBears75 <- allelematch::amUnique(loadedData75$Data, multilocusMap = loadedData75$AlleleKey, alleleMismatch = 10) # changed cutoff to 10 to be more stringent
saveRDS(uniqueBears75, file = "uniqueBears75_10.rds")
allelematch::summary.amUnique(object = uniqueBears75, html = "unique_bears_75_10_v1.html")
allelematch::summary.amUnique(object = uniqueBears75, csv = "unique_bears_75_10_v1.csv")
```

# Cluster all working samples (>= 67 working loci) and identify samples/clusters to be removed:
```{r}
# Create vector of high quality samples to be removed:
rmSamples75 <- c()

# Unmatched (not different enough to be their own individuals and not similar enough to anything else). Remove:
View(data.frame(Sample = uniqueBears75$unclassified$index, uniqueBears75$unclassified$multilocus))
rmSamples75 <- c(rmSamples75, uniqueBears75$unclassified$index)

# Matches several genotypes. Remove:
View(data.frame(Sample = uniqueBears75$multipleMatches$index, uniqueBears75$multipleMatches$multilocus))
rmSamples75 <- c(rmSamples75, uniqueBears75$multipleMatches$index)

# Record number of samples removed:
removedSampleInfo$nUncMultm75 <- length(rmSamples75)

# Cluster all except the removed samples:
loadedDataAll <- LoadAMData(presentGenotypesAll[!(presentGenotypesAll$Sample %in% rmSamples75),])
uniqueBearsAll <- allelematch::amUnique(loadedDataAll$Data, multilocusMap = loadedDataAll$AlleleKey, alleleMismatch = 10) # use stringent 10
allelematch::summary.amUnique(object = uniqueBearsAll, html = "unique_bears_all_10_v1.html")
allelematch::summary.amUnique(object = uniqueBearsAll, csv = "unique_bears_all_10_v1.csv")

# get all clusters from both runs:
clustersAll <- lapply(uniqueBearsAll$pairwise, function(x) {x$match$index})
clusters75 <- lapply(uniqueBears75$pairwise, function(x) {x$match$index})

# check each one and see if they contain any matched sample from '75' run, note all samples in any who doesn't
GetOrphans <- function(hiqClusters, allClusters, rmSamplesHiq) {
  realClusters <- 0
  rmSamples <- c()
  clusteredHiq <- unique(do.call(c, hiqClusters))
  clusteredHiq <- clusteredHiq[!(clusteredHiq %in% rmSamplesHiq)] # remove samples in supplied remove vector
  for(curCluster in allClusters) {
    if(any(curCluster %in% clusteredHiq)) {
      realClusters <- realClusters + 1
    } else {
      rmSamples <- c(rmSamples, curCluster)
      # print(curCluster %in% rmSamples)
    }
  }
  rmSamplesFull <- c(rmSamples, rmSamplesHiq) # add condemned samples from supplied vector
  return(list(numClusters = realClusters, oldRmSamples = unique(rmSamplesHiq), newRmSamples = unique(rmSamples), updatedRmList = unique(rmSamplesFull)))
}

# Add unclassified and multiplematched samples from all run to the untrusted samples and record them:
rmSamplesPre <- c(rmSamples75, uniqueBearsAll$unclassified$index, uniqueBearsAll$multipleMatches$index)
removedSampleInfo$nUncMultmAll <- length(c(uniqueBearsAll$unclassified$index, uniqueBearsAll$multipleMatches$index))

# Get orphaned samples and record them:
orphanData <- GetOrphans(hiqClusters = clusters75, allClusters = clustersAll, rmSamplesHiq = rmSamplesPre)
print(orphanData$numClusters) # number of real clusters
length(orphanData$newRmSamples) # number of newly added samples to be removed
length(orphanData$updatedRmList) # number of samples to be removed
removedSampleInfo$nOrphaned <- length(unique(orphanData$newRmSamples))
rmSamplesAll <- orphanData$updatedRmList
```

# Recluster without samples chosen to be removed:
```{r}
library(readxl)

# Import file with samples to be manually removed (optional):
manualRmFile <- "../list_of_samples.xlsx" # specify file with samples to be removed
geoProblems <- ifelse(manualRmFile %in% list.dirs('.'), readxl::read_excel(manualRmFile), data.frame(SEP = c()))
removedSampleInfo$nManualRm <- sum(!(geoProblems$SEP %in% rmSamplesAll))
rmSamplesAll <- unique(c(rmSamplesAll, geoProblems$SEP)) # problematic that rmSamplesAll is reused here

# Rerun analysis without noted samples:
loadedDataFilt <- LoadAMData(presentGenotypesAll[!(presentGenotypesAll$Sample %in% rmSamplesAll),])
uniqueBearsFilt <- allelematch::amUnique(loadedDataFilt$Data, multilocusMap = loadedDataFilt$AlleleKey, alleleMismatch = 10) # use stringent 10

# Identify orphans, uncalssified and  multiple matches:
clustersFilt <- lapply(uniqueBearsFilt$pairwise, function(x) {x$match$index}) # get clusters from filt run
rmSamplesFilt <- c(rmSamplesAll, uniqueBearsFilt$unclassified$index, uniqueBearsFilt$multipleMatches$index)
orphanDataFilt <- GetOrphans(hiqClusters = clusters75, allClusters = clustersFilt, rmSamplesHiq = rmSamplesFilt)
removedSampleInfo$nOrphaned <- sum(removedSampleInfo$nOrphaned, length(unique(orphanDataFilt$newRmSamples))) # add orphans to the pile
removedSampleInfo$nUncMultmFilt <- length(c(uniqueBearsFilt$unclassified$index, uniqueBearsFilt$multipleMatches$index))

# Rerun again without all samples chosen to be removed
loadedDataFilt <- LoadAMData(presentGenotypesAll[!(presentGenotypesAll$Sample %in% orphanDataFilt$updatedRmList),])
uniqueBearsFilt <- allelematch::amUnique(loadedDataFilt$Data, multilocusMap = loadedDataFilt$AlleleKey, alleleMismatch = 10) # use stringent 10
allelematch::summary.amUnique(object = uniqueBearsFilt, html = "unique_bears_filt_10_v1.html")
allelematch::summary.amUnique(object = uniqueBearsFilt, html = "unique_bears_filt_10_v1.csv")
```

